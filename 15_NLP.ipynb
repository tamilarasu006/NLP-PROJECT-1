{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVAUjx79uIv4",
        "outputId": "04bfead3-2aea-44d0-e983-89451354ec53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- ORIGINAL TEXT -----\n",
            " \n",
            "Artificial Intelligence is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\n",
            "The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n",
            "AI is being used in many industries such as healthcare, finance, education, and robotics.\n",
            "\n",
            "\n",
            "----- SUMMARY -----\n",
            " \n",
            "Artificial Intelligence is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import nltk\n",
        "import heapq\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from string import punctuation\n",
        "\n",
        "# Download required NLTK data (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"\n",
        "Artificial Intelligence is the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\n",
        "The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n",
        "AI is being used in many industries such as healthcare, finance, education, and robotics.\n",
        "\"\"\"\n",
        "\n",
        "# Step 1: Tokenize sentences and words\n",
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text.lower())\n",
        "\n",
        "# Step 2: Remove stopwords and punctuation\n",
        "stop_words = set(stopwords.words(\"english\") + list(punctuation))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Step 3: Compute word frequency\n",
        "word_frequencies = {}\n",
        "for word in filtered_words:\n",
        "    if word not in word_frequencies:\n",
        "        word_frequencies[word] = 1\n",
        "    else:\n",
        "        word_frequencies[word] += 1\n",
        "\n",
        "# Step 4: Score sentences\n",
        "sentence_scores = {}\n",
        "for sentence in sentences:\n",
        "    for word in word_tokenize(sentence.lower()):\n",
        "        if word in word_frequencies:\n",
        "            if sentence not in sentence_scores:\n",
        "                sentence_scores[sentence] = word_frequencies[word]\n",
        "            else:\n",
        "                sentence_scores[sentence] += word_frequencies[word]\n",
        "\n",
        "# Step 5: Select top sentences for summary\n",
        "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "# Step 6: Print summary\n",
        "summary = \" \".join(summary_sentences)\n",
        "print(\"\\n----- ORIGINAL TEXT -----\\n\", text)\n",
        "print(\"\\n----- SUMMARY -----\\n\", summary)"
      ]
    }
  ]
}